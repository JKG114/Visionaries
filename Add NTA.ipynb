{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In this notebook we add American Census collected economic data to each entry of our dataset. Specifically, we \n",
    "#determine which American Census Bureau defined neighborhod the start and end bike-stations are located in, and then\n",
    "#add the start and end neighborhoods, the boroughs of those neighborhoods, and the median incomes of those \n",
    "#neighborhoods to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time \n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Neighborhood Tabulation Area defined neighborhoods (ACB defined) shape file as geopandas dataframe.\n",
    "fname = \"nycgiszoningfeatures_201711shp/nynta.shp\"\n",
    "#standard coordinate system\n",
    "coord_system = {'init': 'epsg:4326'}\n",
    "ntas = gpd.read_file(fname).to_crs(coord_system)\n",
    "#Keep wanted boroughs and Reset index (boroughs with Citi bikes)\n",
    "ntas = ntas.loc[ntas['BoroName'].isin(['Queens','Brooklyn', 'Manhattan'])]\n",
    "\n",
    "#Reindex dataframe\n",
    "ntas=ntas.reset_index(drop=True)\n",
    "#Rename NTACode to GeoID to merge with economic data(see below)\n",
    "ntas.rename(columns={'NTACode': 'GeoID'}, inplace=True)\n",
    "ntas.rename(columns={'NTAName': 'Neighborhood'}, inplace = True)\n",
    "nta = ntas[['Neighborhood', 'GeoID', 'geometry']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in corresponding NTA financial data from nta folder: nynta_17d\n",
    "# :eco2013acs5yrntadata.csv from \n",
    "# http://catalog.opendata.city/hr/dataset/nyc-neighborhood-acs-economic-data/resource/671ebb5a-672e-4005-9712-45310afd4308\n",
    "ecos = pd.read_csv('nynta_17d/eco2013acs5yrntadata.csv', encoding = 'latin1')\n",
    "\n",
    "#Keep desired columns\n",
    "eco = ecos[['GeoID','Borough', 'MdHHIncE']]\n",
    "\n",
    "#Keep wanted boroughs and Reset index\n",
    "eco = eco.loc[eco['Borough'].isin(['Queens','Brooklyn', 'Manhattan'])]\n",
    "eco = eco.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Change string values to numberic and rename\n",
    "md = eco['MdHHIncE']\n",
    "eco['MdHHIncE'] = pd.to_numeric((md.str.replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the economic neighborhood data and the NTA data on the 'GeoID' column. \n",
    "# Note, no reindexing is required\n",
    "result = pd.merge(nta, eco,on='GeoID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GeoFrame Helper functions\n",
    "#These two functions take the start station long and lat and turn them into shapely geometry points\n",
    "def make_start_points(row):\n",
    "    return Point(row['start station longitude'], row['start station latitude'])\n",
    "def make_end_points(row):\n",
    "    return Point(row['end station longitude'], row['end station latitude'])\n",
    "\n",
    "#Takes a data frame and returns a GeoDataFrame with the same data, and \n",
    "#where the long/lat points are the 'geometry' for the GeoDataFrame\n",
    "def make_geoframe(df):\n",
    "    star=time.time()\n",
    "\n",
    "    points = df.apply(make_start_points, axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry = points)\n",
    "    gdf = gdf.rename(columns={'geometry': 'start point'}).set_geometry('start point')\n",
    "    points = df.apply(make_end_points, axis=1)\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry = points)\n",
    "    gdf = gdf.rename(columns={'geometry': 'end point'}).set_geometry('end point')\n",
    "\n",
    "    #Define CRS\n",
    "    gdf.crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "    end=time.time()\n",
    "    print('took', end-star, 'seconds to run...')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case you want to add more Census data, the census csvs are available in zip format. You don't have\n",
    "# to write a new function like the one below, we've done the hard work for you! \n",
    "\n",
    "# Use the census dictionary csvs to identify the neighborhood data traits you want to use. Import the csv with the \n",
    "# data you want and create a dataframe. Create a dataframe with only the columns you want (e.g. 'vacant housing\n",
    "# units) and the 'GeoID' column. \n",
    "\n",
    "# Merge that dataframe with NTA GPD df defined above. Just like with income data, merge on the shared 'GeoID' so that \n",
    "# you get the corresponding neighborhoods for the GeoID's. It will now just be a matter of merging this dataframe\n",
    "# on the bikeset dataframe twice. Once on the 'start neighborhood' column and once on the 'end neighborhood' \n",
    "# column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each row in a dataframe('data') adds the neighborhood and the associated neighborhood data \n",
    "#for the start and end bike stations \n",
    "def Add_Start_Station_Finance_And_Neighborhood12(data):\n",
    "    star=time.time()\n",
    "\n",
    "    #Create two GPD DF's with start points and end points being being the only columns and geometries\n",
    "    start_points = gpd.GeoDataFrame(data['start point'], geometry = data['start point'])\n",
    "    end_points = gpd.GeoDataFrame(data['end point'], geometry = data['end point'])\n",
    "    \n",
    "    #Create Series to hold the start and end neighborhood strings\n",
    "    start_neighborhood =  pd.Series(['NA' for i in range(len(start_points))])\n",
    "    end_neighborhood = pd.Series(['NA' for i in range(len(start_points))])\n",
    "    \n",
    "    #Create Series to hold the start and end borough strings\n",
    "    start_borough = pd.Series(['NA' for i in range(len(start_points))])\n",
    "    end_borough = pd.Series(['NA' for i in range(len(start_points))])\n",
    "    \n",
    "    #Create Series to hold the start and end income values\n",
    "    start_neighborhood_MdHHIncE = pd.Series([0 for i in range(len(start_points))])\n",
    "\n",
    "    end_neighborhood_MdHHIncE = pd.Series([0 for i in range(len(start_points))])\n",
    "\n",
    "    #A counter variable to track/provide the nta neighborhood and associated information \n",
    "    #we  will add to our argument dataframe('data')\n",
    "    count = 0\n",
    "\n",
    "    #Iterate through each of the NTA neighborhood geometries and get the\n",
    "    #start stations located in that geometry and end stations located in that geometry\n",
    "        #Note result was defined above in the 5th cell: it is a GPD df with neighborhoods, their \n",
    "        #geometries, their borough, and their economic data.\n",
    "    for j in result.geometry:\n",
    "        temps = start_points[start_points.within(j)].index\n",
    "        tempe = end_points[end_points.within(j)].index\n",
    "\n",
    "    \n",
    "        #Store information for the jth neighborhood in temporary series associated with the stations\n",
    "        #located in the jth neighborhood\n",
    "        start_neighborhood[temps] = result['Neighborhood'][count]\n",
    "        start_borough[temps] = result['Borough'][count]\n",
    "        start_neighborhood_MdHHIncE[temps] = result['MdHHIncE'][count]\n",
    "\n",
    "        end_neighborhood[tempe] = result['Neighborhood'][count]\n",
    "        end_borough[tempe] = result['Borough'][count]\n",
    "        end_neighborhood_MdHHIncE[tempe] = result['MdHHIncE'][count]\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    #Add columns with NTA info to 'data'        \n",
    "    data['start neighborhood'] = start_neighborhood\n",
    "    data['start borough'] = start_borough\n",
    "    data['start median income'] = start_neighborhood_MdHHIncE\n",
    "    \n",
    "    data['end neighborhood'] = end_neighborhood\n",
    "    data['end borough'] = end_borough\n",
    "    data['end median income'] = end_neighborhood_MdHHIncE\n",
    "\n",
    "    end=time.time()\n",
    "    print('took', end-star, 'seconds to run...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 111.8298659324646 seconds to run...\n",
      "took 5933.925531864166 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to April CSV\n",
    "\n",
    "April=pd.read_csv('FinalData/April_2016.csv')\n",
    "August.columns = map(str.lower, August.columns)\n",
    "April = make_geoframe(April)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(April)\n",
    "\n",
    "#Surprisingly, some points are not contained in neighborhoods! (A few stations are lcoated in Jersey,\n",
    "#We did not study these stations, which was fine since jersey bikes rarely enter NYC and vice-versa.)\n",
    "#We dropped the rows with stations located in Jersey.\n",
    "\n",
    "April = April[April['end neighborhood'] != 'NA']\n",
    "April = April[April['start neighborhood'] != 'NA']\n",
    "April=April.reset_index(drop=True)\n",
    "April.to_csv('April_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 143.19871520996094 seconds to run...\n",
      "took 5914.577415943146 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to August CSV\n",
    "\n",
    "August=pd.read_csv('FinalData/August_2016.csv')\n",
    "August.columns = map(str.lower, August.columns)\n",
    "August = make_geoframe(August)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(August)\n",
    "August = August[August['end neighborhood'] != 'NA']\n",
    "August = August[August['start neighborhood'] != 'NA']\n",
    "August=August.reset_index(drop=True)\n",
    "August.to_csv('August_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 100.42866826057434 seconds to run...\n",
      "took 5201.549489021301 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to December CSV\n",
    "\n",
    "December=pd.read_csv('FinalData/December_2016.csv')\n",
    "December.columns = map(str.lower, December.columns)\n",
    "December = make_geoframe(December)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(December)\n",
    "December = December[December['end neighborhood'] != 'NA']\n",
    "December = December[December['start neighborhood'] != 'NA']\n",
    "December=December.reset_index(drop=True)\n",
    "December.to_csv('December_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 64.71481895446777 seconds to run...\n",
      "took 3349.4047288894653 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to February CSV\n",
    "\n",
    "February=pd.read_csv('FinalData/February_2016.csv')\n",
    "February.columns = map(str.lower, February.columns)\n",
    "February = make_geoframe(February)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(February)\n",
    "February = February[February['end neighborhood'] != 'NA']\n",
    "February = February[February['start neighborhood'] != 'NA']\n",
    "February=February.reset_index(drop=True)\n",
    "February.to_csv('February_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 60.362560987472534 seconds to run...\n",
      "took 3047.705817937851 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to January CSV\n",
    "\n",
    "January=pd.read_csv('FinalData/January_2016.csv')\n",
    "January.columns = map(str.lower, January.columns)\n",
    "January = make_geoframe(January)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(January)\n",
    "January = January[January['end neighborhood'] != 'NA']\n",
    "January = January[January['start neighborhood'] != 'NA']\n",
    "January=January.reset_index(drop=True)\n",
    "January.to_csv('January_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 148.92507600784302 seconds to run...\n",
      "took 7696.264832019806 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to July CSV\n",
    "\n",
    "July=pd.read_csv('FinalData/July_2016.csv')\n",
    "July.columns = map(str.lower, July.columns)\n",
    "July = make_geoframe(July)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(July)\n",
    "July = July[July['end neighborhood'] != 'NA']\n",
    "July = July[July['start neighborhood'] != 'NA']\n",
    "July=July.reset_index(drop=True)\n",
    "July.to_csv('July_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 163.55002188682556 seconds to run...\n",
      "took 8273.517446279526 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to June CSV\n",
    "\n",
    "June=pd.read_csv('FinalData/June_2016.csv')\n",
    "June.columns = map(str.lower, June.columns)\n",
    "June = make_geoframe(June)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(June)\n",
    "June = June[June['end neighborhood'] != 'NA']\n",
    "June = June[June['start neighborhood'] != 'NA']\n",
    "June=June.reset_index(drop=True)\n",
    "June.to_csv('June_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 101.18156123161316 seconds to run...\n",
      "took 5306.189533948898 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to March CSV\n",
    "\n",
    "March=pd.read_csv('FinalData/March_2016.csv')\n",
    "March.columns = map(str.lower, March.columns)\n",
    "March = make_geoframe(March)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(March)\n",
    "March = March[March['end neighborhood'] != 'NA']\n",
    "March = March[March['start neighborhood'] != 'NA']\n",
    "March=March.reset_index(drop=True)\n",
    "March.to_csv('March_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 148.23473572731018 seconds to run...\n",
      "took 6671.4576761722565 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to May CSV\n",
    "\n",
    "May=pd.read_csv('FinalData/May_2016.csv')\n",
    "May.columns = map(str.lower, May.columns)\n",
    "May = make_geoframe(May)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(May)\n",
    "May = May[May['end neighborhood'] != 'NA']\n",
    "May = May[May['start neighborhood'] != 'NA']\n",
    "May=May.reset_index(drop=True)\n",
    "May.to_csv('May_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 137.36907410621643 seconds to run...\n",
      "took 7348.719714164734 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to November CSV\n",
    "\n",
    "November=pd.read_csv('FinalData/November_2016.csv')\n",
    "November.columns = map(str.lower, November.columns)\n",
    "November = make_geoframe(November)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(November)\n",
    "November = November[November['end neighborhood'] != 'NA']\n",
    "November = November[November['start neighborhood'] != 'NA']\n",
    "November=November.reset_index(drop=True)\n",
    "November.to_csv('November_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 245.97137904167175 seconds to run...\n",
      "took 9540.511973142624 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to October CSV\n",
    "\n",
    "October=pd.read_csv('FinalData/October_2016.csv')\n",
    "October.columns = map(str.lower, October.columns)\n",
    "October = make_geoframe(October)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(October)\n",
    "October = October[October['end neighborhood'] != 'NA']\n",
    "October = October[October['start neighborhood'] != 'NA']\n",
    "October=October.reset_index(drop=True)\n",
    "October.to_csv('October_2016_MDincome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 437.0577619075775 seconds to run...\n",
      "took 12574.982161998749 seconds to run...\n"
     ]
    }
   ],
   "source": [
    "#Add neighborhoods and Median Income to September CSV\n",
    "\n",
    "September=pd.read_csv('FinalData/September_2016.csv')\n",
    "September.columns = map(str.lower, September.columns)\n",
    "September = make_geoframe(September)\n",
    "Add_Start_Station_Finance_And_Neighborhood12(September)\n",
    "September = September[September['end neighborhood'] != 'NA']\n",
    "September = September[September['start neighborhood'] != 'NA']\n",
    "September=September.reset_index(drop=True)\n",
    "September.to_csv('September_2016_MDincome.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
